{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aaarrti/ISS/blob/main/notebooks/example_electricity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JaoLRvkHtXs"
      },
      "source": [
        "# Part 1. Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Ywm_2DLHI1fY"
      },
      "outputs": [],
      "source": [
        "from google.colab import auth\n",
        "\n",
        "auth.authenticate_user()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtoemg7aL0j1"
      },
      "source": [
        "Install TFT re-implementation from git, until it is released."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-ynBPBAIL7rn",
        "outputId": "4c28fca7-89a9-4355-f8ed-cd6a7a4e6b7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: jax 0.4.12\n",
            "Uninstalling jax-0.4.12:\n",
            "  Successfully uninstalled jax-0.4.12\n",
            "Found existing installation: jaxlib 0.4.12\n",
            "Uninstalling jaxlib-0.4.12:\n",
            "  Successfully uninstalled jaxlib-0.4.12\n",
            "Found existing installation: chex 0.1.7\n",
            "Uninstalling chex-0.1.7:\n",
            "  Successfully uninstalled chex-0.1.7\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: keras_tuner in /usr/local/lib/python3.10/dist-packages (1.3.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras_tuner) (23.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras_tuner) (2.27.1)\n",
            "Requirement already satisfied: kt-legacy in /usr/local/lib/python3.10/dist-packages (from keras_tuner) (1.0.5)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->keras_tuner) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->keras_tuner) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->keras_tuner) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->keras_tuner) (3.4)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/aaarrti/tf2_temporal_fusion_transformer.git@dev\n",
            "  Cloning https://github.com/aaarrti/tf2_temporal_fusion_transformer.git (to revision dev) to /tmp/pip-req-build-ced2uc3e\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/aaarrti/tf2_temporal_fusion_transformer.git /tmp/pip-req-build-ced2uc3e\n",
            "  Running command git checkout -b dev --track origin/dev\n",
            "  Switched to a new branch 'dev'\n",
            "  Branch 'dev' set up to track remote branch 'dev' from 'origin'.\n",
            "  Resolved https://github.com/aaarrti/tf2_temporal_fusion_transformer.git to commit 4f4c4aca823276ad6c3e7fdce2aad5818a1ef22d\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (from temporal_fusion_transformer==0.0.1) (2.12.0)\n",
            "Requirement already satisfied: keras_pbar in /usr/local/lib/python3.10/dist-packages (from temporal_fusion_transformer==0.0.1) (0.0.1)\n",
            "Requirement already satisfied: scikit_learn in /usr/local/lib/python3.10/dist-packages (from temporal_fusion_transformer==0.0.1) (1.2.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from temporal_fusion_transformer==0.0.1) (1.5.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from temporal_fusion_transformer==0.0.1) (3.7.1)\n",
            "Requirement already satisfied: matplotx in /usr/local/lib/python3.10/dist-packages (from temporal_fusion_transformer==0.0.1) (0.3.10)\n",
            "Requirement already satisfied: jaxtyping in /usr/local/lib/python3.10/dist-packages (from temporal_fusion_transformer==0.0.1) (0.2.20)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.10/dist-packages (from jaxtyping->temporal_fusion_transformer==0.0.1) (1.23.5)\n",
            "Requirement already satisfied: typeguard>=2.13.3 in /usr/local/lib/python3.10/dist-packages (from jaxtyping->temporal_fusion_transformer==0.0.1) (4.0.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.1 in /usr/local/lib/python3.10/dist-packages (from jaxtyping->temporal_fusion_transformer==0.0.1) (4.6.3)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from keras_pbar->temporal_fusion_transformer==0.0.1) (2.12.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->temporal_fusion_transformer==0.0.1) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->temporal_fusion_transformer==0.0.1) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->temporal_fusion_transformer==0.0.1) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->temporal_fusion_transformer==0.0.1) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->temporal_fusion_transformer==0.0.1) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->temporal_fusion_transformer==0.0.1) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->temporal_fusion_transformer==0.0.1) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->temporal_fusion_transformer==0.0.1) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->temporal_fusion_transformer==0.0.1) (2022.7.1)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit_learn->temporal_fusion_transformer==0.0.1) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit_learn->temporal_fusion_transformer==0.0.1) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit_learn->temporal_fusion_transformer==0.0.1) (3.1.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->temporal_fusion_transformer==0.0.1) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->temporal_fusion_transformer==0.0.1) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->temporal_fusion_transformer==0.0.1) (23.3.3)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->temporal_fusion_transformer==0.0.1) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->temporal_fusion_transformer==0.0.1) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow->temporal_fusion_transformer==0.0.1) (1.54.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->temporal_fusion_transformer==0.0.1) (3.8.0)\n",
            "Collecting jax>=0.3.15 (from tensorflow->temporal_fusion_transformer==0.0.1)\n",
            "  Using cached jax-0.4.12-py3-none-any.whl\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->temporal_fusion_transformer==0.0.1) (16.0.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow->temporal_fusion_transformer==0.0.1) (3.3.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow->temporal_fusion_transformer==0.0.1) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow->temporal_fusion_transformer==0.0.1) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->temporal_fusion_transformer==0.0.1) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow->temporal_fusion_transformer==0.0.1) (2.12.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->temporal_fusion_transformer==0.0.1) (2.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->temporal_fusion_transformer==0.0.1) (2.3.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow->temporal_fusion_transformer==0.0.1) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow->temporal_fusion_transformer==0.0.1) (0.32.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow->temporal_fusion_transformer==0.0.1) (0.40.0)\n",
            "Requirement already satisfied: ml-dtypes>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow->temporal_fusion_transformer==0.0.1) (0.1.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow->temporal_fusion_transformer==0.0.1) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow->temporal_fusion_transformer==0.0.1) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow->temporal_fusion_transformer==0.0.1) (3.4.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow->temporal_fusion_transformer==0.0.1) (2.27.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow->temporal_fusion_transformer==0.0.1) (0.7.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow->temporal_fusion_transformer==0.0.1) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow->temporal_fusion_transformer==0.0.1) (2.3.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow->temporal_fusion_transformer==0.0.1) (5.3.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow->temporal_fusion_transformer==0.0.1) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow->temporal_fusion_transformer==0.0.1) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow->temporal_fusion_transformer==0.0.1) (1.3.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow->temporal_fusion_transformer==0.0.1) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow->temporal_fusion_transformer==0.0.1) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow->temporal_fusion_transformer==0.0.1) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow->temporal_fusion_transformer==0.0.1) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow->temporal_fusion_transformer==0.0.1) (2.1.2)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow->temporal_fusion_transformer==0.0.1) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow->temporal_fusion_transformer==0.0.1) (3.2.2)\n",
            "Installing collected packages: jax\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "dopamine-rl 4.0.6 requires jaxlib>=0.1.51, which is not installed.\n",
            "optax 0.1.5 requires chex>=0.1.5, which is not installed.\n",
            "optax 0.1.5 requires jaxlib>=0.1.37, which is not installed.\n",
            "orbax-checkpoint 0.2.1 requires jaxlib, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed jax-0.4.12\n"
          ]
        }
      ],
      "source": [
        "# Hide jax, since we don't use it here.\n",
        "!python -m pip uninstall --yes jax jaxlib chex optax orbax-checkpoint dopamine-rl\n",
        "!python -m pip install -U keras_tuner\n",
        "!python -m pip install 'git+https://github.com/aaarrti/tf2_temporal_fusion_transformer.git@dev'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Le-3eIi7mz09"
      },
      "outputs": [],
      "source": [
        "%load_ext tensorboard\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ILHCIednCXHg"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from keras.utils.tf_utils import can_jit_compile, set_random_seed\n",
        "from keras.callbacks import TensorBoard, TerminateOnNaN, BackupAndRestore\n",
        "from temporal_fusion_transformer.experiments import electricity_experiment\n",
        "from temporal_fusion_transformer.tf.quantile_loss import QuantileLoss, QuantileRMSE\n",
        "from temporal_fusion_transformer.utils import map_dict, filter_dict, make_tft_model\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import keras_tuner as kt\n",
        "import pickle\n",
        "import matplotx\n",
        "from temporal_fusion_transformer.plotting import plot_predictions\n",
        "from keras.api.keras.experimental import CosineDecay\n",
        "\n",
        "plt.style.use(matplotx.styles.duftify(matplotx.styles.dracula))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z5LhsB8cMKRZ",
        "outputId": "ec534142-6d0a-447a-9777-d7d7746b16da"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[LogicalDevice(name='/device:CPU:0', device_type='CPU'),\n",
              " LogicalDevice(name='/job:worker/replica:0/task:0/device:CPU:0', device_type='CPU'),\n",
              " LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU_SYSTEM:0', device_type='TPU_SYSTEM'),\n",
              " LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:0', device_type='TPU'),\n",
              " LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:1', device_type='TPU'),\n",
              " LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:2', device_type='TPU'),\n",
              " LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:3', device_type='TPU'),\n",
              " LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:4', device_type='TPU'),\n",
              " LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:5', device_type='TPU'),\n",
              " LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:6', device_type='TPU'),\n",
              " LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:7', device_type='TPU'),\n",
              " LogicalDevice(name='/job:worker/replica:0/task:0/device:XLA_CPU:0', device_type='XLA_CPU')]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
        "tf.config.experimental_connect_to_cluster(tpu)\n",
        "tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "strategy = tf.distribute.TPUStrategy(tpu, experimental_spmd_xla_partitioning=True)\n",
        "tf.config.list_logical_devices()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zw5jT5o4N75s"
      },
      "source": [
        "General setup."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "H9kVJYjKMrAn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f010ae24-4c9e-4316-c040-bb013ae6fb52"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'bfloat16'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "prng_seed = 42\n",
        "epochs = 5\n",
        "# 8 TPU cores\n",
        "batch_size = 512 * 8\n",
        "num_electricity_samples = 1853057\n",
        "steps_per_epoch = num_electricity_samples // batch_size\n",
        "set_random_seed(prng_seed)\n",
        "\n",
        "if can_jit_compile(True):\n",
        "    tf.keras.mixed_precision.set_global_policy(\"mixed_bfloat16\")\n",
        "    tf.config.optimizer.set_jit(\"autoclustering\")\n",
        "\n",
        "compute_dtype = tf.keras.mixed_precision.global_policy().compute_dtype\n",
        "compute_dtype"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qDG11OVN-FF"
      },
      "source": [
        "Load data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "KwitiYl2CXHh"
      },
      "outputs": [],
      "source": [
        "element_spec = {\n",
        "    \"identifier\": tf.TensorSpec([None, 192, 1], dtype=tf.string),\n",
        "    \"time\": tf.TensorSpec([None, 192, 1], dtype=tf.float32),\n",
        "    \"outputs\": tf.TensorSpec([None, 24, 1], dtype=tf.float32),\n",
        "    \"inputs_static\": tf.TensorSpec([None, 1], dtype=tf.int32),\n",
        "    \"inputs_known_real\": tf.TensorSpec([None, 192, 3], dtype=tf.float32),\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcb4fhd0M7T7",
        "outputId": "db1fa4b1-f6e7-45c9-f5b3-a10ba4902a30"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'static': TensorSpec(shape=(4096, 1), dtype=tf.int32, name=None),\n",
              "  'known_real': TensorSpec(shape=(4096, 192, 3), dtype=tf.bfloat16, name=None)},\n",
              " TensorSpec(shape=(4096, 24, 1), dtype=tf.bfloat16, name=None))"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "def map_fn(arg):\n",
        "    return (\n",
        "        dict(\n",
        "            static=arg[\"inputs_static\"],\n",
        "            known_real=tf.cast(arg[\"inputs_known_real\"], compute_dtype),\n",
        "        ),\n",
        "        tf.cast(arg[\"outputs\"], compute_dtype),\n",
        "    )\n",
        "\n",
        "\n",
        "with strategy.scope():\n",
        "    train_ds = (\n",
        "        tf.data.Dataset.from_tensor_slices(\n",
        "            [f\"gs://tf2_tft_v2/data/electricity/train/{i}\" for i in range(19)]\n",
        "        )\n",
        "        .flat_map(lambda i: tf.data.Dataset.load(i, element_spec=element_spec))\n",
        "        .rebatch(batch_size, True)\n",
        "        .map(map_fn, tf.data.AUTOTUNE)\n",
        "        .shuffle(batch_size, prng_seed, True)\n",
        "        .cache()\n",
        "        .repeat(epochs)\n",
        "        .prefetch(tf.data.AUTOTUNE)\n",
        "    )\n",
        "\n",
        "    validation_ds = (\n",
        "        tf.data.Dataset.from_tensor_slices(\n",
        "            [f\"gs://tf2_tft_v2/data/electricity/validation/{i}\" for i in range(3)]\n",
        "        )\n",
        "        .flat_map(lambda i: tf.data.Dataset.load(i, element_spec=element_spec))\n",
        "        .rebatch(batch_size, True)\n",
        "        .map(map_fn, tf.data.AUTOTUNE)\n",
        "        .shuffle(batch_size, prng_seed, True)\n",
        "        .cache()\n",
        "        .repeat(epochs)\n",
        "        .prefetch(tf.data.AUTOTUNE)\n",
        "    )\n",
        "\n",
        "\n",
        "train_ds.element_spec"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AsOCZ6hcOdcA"
      },
      "source": [
        "Look for the best hyperparameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZzLjXYESOekR"
      },
      "outputs": [],
      "source": [
        "def hyper_model(hyper_params: kt.HyperParameters) -> kt.HyperModel:\n",
        "    num_attention_heads = hyper_params.Int(\n",
        "        \"num_attention_heads\",\n",
        "        min_value=1,\n",
        "        max_value=14,\n",
        "        default=electricity_experiment.default_params.num_attention_heads,\n",
        "    )\n",
        "    hidden_layer_size = hyper_params.Int(\n",
        "        \"hidden_layer_size\",\n",
        "        min_value=5,\n",
        "        max_value=25,\n",
        "        default=electricity_experiment.default_params.hidden_layer_size,\n",
        "    )\n",
        "\n",
        "    grad_clip_norm = hyper_params.Boolean(\"grad_clip_norm\")\n",
        "    cosine_decay = hyper_params.Boolean(\"cosine_decay\")\n",
        "\n",
        "    with hyper_params.conditional_scope(\"grad_clip_norm\", True):\n",
        "        if grad_clip_norm:\n",
        "            clip_norm_val = hyper_params.Float(\n",
        "                \"clip_norm_val\",\n",
        "                min_value=0.01,\n",
        "                max_value=10,\n",
        "                sampling=\"log\",\n",
        "                default=electricity_experiment.default_params.max_gradient_norm,\n",
        "            )\n",
        "    with hyper_params.conditional_scope(\"grad_clip_norm\", False):\n",
        "        if not grad_clip_norm:\n",
        "            clip_norm_val = None\n",
        "\n",
        "    with hyper_params.conditional_scope(\"cosine_decay\", True):\n",
        "        if cosine_decay:\n",
        "            init_learning_rate = hyper_params.Float(\n",
        "                \"learning_rate\",\n",
        "                1e-4,\n",
        "                0.01,\n",
        "\n",
        "                sampling=\"log\",\n",
        "                default=electricity_experiment.default_params.learning_rate,\n",
        "            )\n",
        "            decay_steps = hyper_params.Float(\n",
        "                \"decay_steps\", 0.1 * steps_per_epoch, steps_per_epoch, sampling=\"log\"\n",
        "            )\n",
        "            decay_alpha = hyper_params.Float(\"decay_alpha\", 0.1, 0.5, sampling=\"log\")\n",
        "            learning_rate = CosineDecay(init_learning_rate, decay_steps, decay_alpha)\n",
        "\n",
        "    with hyper_params.conditional_scope(\"cosine_decay\", False):\n",
        "        if not cosine_decay:\n",
        "            learning_rate = hyper_params.Float(\n",
        "                \"learning_rate\",\n",
        "                1e-4,\n",
        "                0.01,\n",
        "                sampling=\"log\",\n",
        "                default=electricity_experiment.default_params.learning_rate,\n",
        "            )\n",
        "\n",
        "    hp_model = make_tft_model(\n",
        "        electricity_experiment,\n",
        "        unroll_lstm=True,\n",
        "        num_attention_heads=num_attention_heads,\n",
        "        hidden_layer_size=hidden_layer_size,\n",
        "        prng_seed=prng_seed,\n",
        "    )\n",
        "\n",
        "    hp_model.compile(\n",
        "        optimizer=tf.keras.optimizers.Adam(\n",
        "            learning_rate=learning_rate,\n",
        "            jit_compile=can_jit_compile(True),\n",
        "            clipnorm=clip_norm_val,\n",
        "        ),\n",
        "        loss=QuantileLoss(hp_model.quantiles),\n",
        "        jit_compile=can_jit_compile(True),\n",
        "        metrics=[QuantileRMSE(hp_model.quantiles)],\n",
        "    )\n",
        "    return hp_model\n",
        "\n",
        "\n",
        "with strategy.scope():\n",
        "    tuner: kt.Hyperband = kt.Hyperband(\n",
        "        hyper_model,\n",
        "        objective=kt.Objective(\"quantile_rmse\", direction=\"min\"),\n",
        "        max_epochs=epochs,\n",
        "        factor=3,\n",
        "        directory=\"gs://tf2_tft_v2/logs/keras_tuner\",\n",
        "        project_name=\"tft_electricity\",\n",
        "        max_consecutive_failed_trials=1,\n",
        "        seed=prng_seed,\n",
        "    )\n",
        "\n",
        "    tuner.search(\n",
        "        train_ds,\n",
        "        epochs=epochs,\n",
        "        validation_data=validation_ds,\n",
        "        callbacks=[\n",
        "            TensorBoard(\n",
        "                \"gs://tf2_tft_v2/logs/tensorboard\",\n",
        "                update_freq=10,\n",
        "                write_steps_per_second=True,\n",
        "            ),\n",
        "            TerminateOnNaN(),\n",
        "            BackupAndRestore(\"gs://tf2_tft_v2/logs/checkpoints\"),\n",
        "        ],\n",
        "        steps_per_epoch=steps_per_epoch,\n",
        "    )\n",
        "\n",
        "    best_hps = tuner.get_best_hyperparameters()[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train model with best hyperparameters."
      ],
      "metadata": {
        "collapsed": false,
        "id": "GOlZ-u2CCXHi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "model = tuner.hypermodel.build(best_hps)\n",
        "history = model.fit(\n",
        "    train_ds,\n",
        "    epochs=epochs,\n",
        "    validation_data=validation_ds,\n",
        "    callbacks=[\n",
        "        TensorBoard(\n",
        "            \"gs://tf2_tft_v2/logs/tensorboard\",\n",
        "            update_freq=10,\n",
        "            write_steps_per_second=True,\n",
        "        ),\n",
        "        TerminateOnNaN(),\n",
        "        BackupAndRestore(\"gs://tf2_tft_v2/logs/checkpoints\"),\n",
        "    ],\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        ")"
      ],
      "metadata": {
        "id": "42KYj6tNCXHi"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XDvTigIxO53B"
      },
      "source": [
        "Launch tensorboard."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NcVR6gcZO_GU"
      },
      "outputs": [],
      "source": [
        "%tensorboard --logdir \"gs://tf2_tft_v2/logs/tensorboard/\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDG-DpK9O7-f"
      },
      "source": [
        "Save weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m4hfOkGaO92b"
      },
      "outputs": [],
      "source": [
        "model.save_weights(\"gs://tf2_tft_v2/data/electricity/weights_v1.keras\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPsUoC-zKkWb"
      },
      "source": [
        "# Part 2. Inference and explanations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "with open(\"../data/electricity/scalers.pickle\", \"rb\") as file:\n",
        "    target_scaler: StandardScaler = pickle.load(file, fix_imports=True).target[\"MT_001\"]"
      ],
      "metadata": {
        "id": "q5VT_7X7CXHi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HfGSMfAuCXHi"
      },
      "outputs": [],
      "source": [
        "# TODO: update experiment with best hyper params.\n",
        "model = make_tft_model(electricity_experiment)\n",
        "# model.load_weights(\"gs://tf2_tft_v2/data/electricity/weights/weights\")\n",
        "model.jit_compile = can_jit_compile(True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ylrX9-EPCXHi"
      },
      "outputs": [],
      "source": [
        "batch_size = 64\n",
        "\n",
        "test_ds = (\n",
        "    tf.data.Dataset.load(\"../data/electricity/test/0\")\n",
        "    .rebatch(batch_size, True)\n",
        "    .as_numpy_iterator()\n",
        "    .next()\n",
        ")\n",
        "map_dict(test_ds, value_mapper=np.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2zlNGdc_CXHi"
      },
      "outputs": [],
      "source": [
        "# Make sure we do prediction for 1 entity.\n",
        "test_ds[\"identifier\"][..., 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dej2DUYjCXHi"
      },
      "outputs": [],
      "source": [
        "t = test_ds[\"time\"]\n",
        "outputs = test_ds[\"outputs\"]\n",
        "\n",
        "\n",
        "def rename_inputs(arg):\n",
        "    if arg == \"inputs_static\":\n",
        "        return \"static\"\n",
        "    if arg == \"inputs_known_real\":\n",
        "        return \"known_real\"\n",
        "\n",
        "\n",
        "x_batch = map_dict(\n",
        "    filter_dict(\n",
        "        test_ds, key_filter=lambda k: k in (\"inputs_static\", \"inputs_known_real\")\n",
        "    ),\n",
        "    key_mapper=rename_inputs,\n",
        ")\n",
        "map_dict(x_batch, np.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "outputs": [],
      "source": [
        "logits = model.predict(\n",
        "    x_batch,\n",
        "    batch_size=batch_size,\n",
        ")\n",
        "# q_01_logits, q_05_logits, q_09_logits = logits[...,0], logits[...,1], logits[...,2]\n",
        "\n",
        "past_time = t[:, : model.num_encoder_steps, 0]\n",
        "past_outputs = outputs[:, : model.num_encoder_steps]\n",
        "\n",
        "look_ahead_time = t[:, model.num_encoder_steps :, 0]\n",
        "look_ahead_outputs = outputs[:, model.num_encoder_steps :]\n",
        "\n",
        "\n",
        "def scale_target(_, arr):\n",
        "    return target_scaler.inverse_transform(arr)\n",
        "\n",
        "\n",
        "with plt.style.context(matplotx.styles.duftify(matplotx.styles.dracula)):\n",
        "    plot_predictions(\n",
        "        predicted_outputs=logits,\n",
        "        future_timestamps=look_ahead_time,\n",
        "        past_outputs=past_outputs,\n",
        "        past_time_stamps=past_time,\n",
        "        target_scaler=scale_target,\n",
        "        num_outputs=1,\n",
        "        quantiles=model.quantiles,\n",
        "        future_outputs=look_ahead_outputs,\n",
        "    )\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "-xbnnyNnCXHi"
      }
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}